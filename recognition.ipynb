{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f7ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature, filters, morphology, segmentation, measure\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f66d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing detector based on centroids with simplified features...\n",
      "Extracting simple training features...\n",
      "Processing image 1/100...\n",
      "Processing image 21/100...\n",
      "Processing image 41/100...\n",
      "Processing image 61/100...\n",
      "Processing image 81/100...\n",
      "Centroids initialized: Face (6 features), Non-Face (6 features)\n",
      "Facial recognition processor initialized!\n"
     ]
    }
   ],
   "source": [
    "class FaceRecognitionProcessor:\n",
    "    \"\"\"\n",
    "    Main class for facial recognition processing\n",
    "    Uses image processing techniques seen in class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Initializing detector based on centroids with simplified features...\")\n",
    "        self.standard_size = (64, 64)  \n",
    "        self._init_simple_detector()\n",
    "        \n",
    "    def _init_simple_detector(self):\n",
    "        \"\"\"Initializes the detector based on simple statistical features\"\"\"\n",
    "        try:\n",
    "            from skimage import data\n",
    "            images = data.lfw_subset()\n",
    "            \n",
    "            print(\"Extracting simple training features...\")\n",
    "            X = []\n",
    "            for i, img in enumerate(images[:100]): \n",
    "                if i % 20 == 0:\n",
    "                    print(f\"Processing image {i+1}/100...\")\n",
    "                    \n",
    "                img_resized = cv2.resize(img, self.standard_size)\n",
    "                \n",
    "                features = self._extract_simple_features(img_resized)\n",
    "                X.append(features)\n",
    "            \n",
    "            self.centroid_face = np.mean(X[0:50], axis=0) \n",
    "            self.centroid_non_face = np.mean(X[50:100], axis=0) \n",
    "            \n",
    "            print(f\"Centroids initialized: Face ({len(self.centroid_face)} features), Non-Face ({len(self.centroid_non_face)} features)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing centroids: {e}\")\n",
    "            self.centroid_face = np.array([100, 0.5, 0.3, 50, 30, 20]) \n",
    "            self.centroid_non_face = np.array([150, 0.8, 0.6, 80, 60, 40])  \n",
    "            print(f\"Fallback: Basic centroids initialized\")\n",
    "        \n",
    "    def _extract_simple_features(self, image):\n",
    "        \"\"\"Extracts simple and fast statistical features\"\"\"\n",
    "        mean_intensity = np.mean(image)\n",
    "        \n",
    "        std_intensity = np.std(image)\n",
    "        \n",
    "        contrast = np.max(image) - np.min(image)\n",
    "        \n",
    "        energy = np.sum(image**2) / (image.shape[0] * image.shape[1])\n",
    "        \n",
    "        grad_x = np.abs(np.gradient(image.astype(float), axis=1))\n",
    "        grad_y = np.abs(np.gradient(image.astype(float), axis=0))\n",
    "        avg_gradient = np.mean(grad_x + grad_y)\n",
    "        \n",
    "        left_half = image[:, :image.shape[1]//2]\n",
    "        right_half = np.fliplr(image[:, image.shape[1]//2:])\n",
    "        min_width = min(left_half.shape[1], right_half.shape[1])\n",
    "        symmetry = np.mean(np.abs(left_half[:, :min_width] - right_half[:, :min_width]))\n",
    "        \n",
    "        return np.array([mean_intensity, std_intensity/255.0, contrast/255.0, \n",
    "                        energy/65535.0, avg_gradient/255.0, symmetry/255.0])\n",
    "    \n",
    "    def _is_face_region(self, image_region):\n",
    "        \"\"\"Classifies whether a region contains a face using simple feature centroids\"\"\"\n",
    "        if image_region.size == 0:\n",
    "            return False\n",
    "            \n",
    "        resized = cv2.resize(image_region, self.standard_size)\n",
    "        \n",
    "        features = self._extract_simple_features(resized)\n",
    "        \n",
    "        if len(features) != len(self.centroid_face):\n",
    "            return False\n",
    "        \n",
    "        dist_to_face = euclidean(features, self.centroid_face)\n",
    "        dist_to_non_face = euclidean(features, self.centroid_non_face)\n",
    "        \n",
    "        return dist_to_face < dist_to_non_face\n",
    "    \n",
    "    def _find_candidate_regions(self, gray_image):\n",
    "        \"\"\"Finds candidate regions using contour detection\"\"\"\n",
    "        blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "        \n",
    "        equalized = cv2.equalizeHist(blurred)\n",
    "        \n",
    "        edges = cv2.Canny(equalized, 50, 150)\n",
    "        \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "        edges = cv2.morphologyEx(edges, cv2.MORPH_DILATE, kernel)\n",
    "        \n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        candidate_regions = []\n",
    "        min_area = 1500  \n",
    "        max_area = gray_image.shape[0] * gray_image.shape[1] // 6  \n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if min_area < area < max_area:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                \n",
    "                aspect_ratio = w / h\n",
    "                if 0.6 < aspect_ratio < 1.8:  \n",
    "                    margin = max(5, min(w, h) // 20)\n",
    "                    x = max(0, x - margin)\n",
    "                    y = max(0, y - margin)\n",
    "                    w = min(gray_image.shape[1] - x, w + 2*margin)\n",
    "                    h = min(gray_image.shape[0] - y, h + 2*margin)\n",
    "                    \n",
    "                    candidate_regions.append((x, y, w, h))\n",
    "        \n",
    "        return candidate_regions\n",
    "        \n",
    "    def load_image_pairs(self, data_dir):\n",
    "        \"\"\"\n",
    "        Loads image pairs from directory\n",
    "        Looks for A-B pairs where A are originals and B are transformed\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        \n",
    "        a_files = glob.glob(os.path.join(data_dir, \"A*.jpg\")) + glob.glob(os.path.join(data_dir, \"A*.jpeg\"))\n",
    "        b_files = glob.glob(os.path.join(data_dir, \"B*.jpg\")) + glob.glob(os.path.join(data_dir, \"B*.jpeg\"))\n",
    "        \n",
    "        a_files = sorted(a_files)\n",
    "        b_files = sorted(b_files)\n",
    "        \n",
    "        print(f\"Found {len(a_files)} original images (A) and {len(b_files)} transformed images (B)\")\n",
    "        \n",
    "        for a_file in a_files:\n",
    "            a_name = os.path.basename(a_file)\n",
    "            import re\n",
    "            a_match = re.search(r'A(\\d+)', a_name)\n",
    "            \n",
    "            if a_match:\n",
    "                number = a_match.group(1)\n",
    "                b_pattern = f\"B{number}\"\n",
    "                \n",
    "                matching_b = [b for b in b_files if b_pattern in os.path.basename(b)]\n",
    "                \n",
    "                if matching_b:\n",
    "                    pairs.append((a_file, matching_b[0]))\n",
    "                    print(f\"Pair created: {os.path.basename(a_file)} <-> {os.path.basename(matching_b[0])}\")\n",
    "        \n",
    "        if not pairs:\n",
    "            print(\"No A-B pairs found! Creating sequential pairs...\")\n",
    "            min_len = min(len(a_files), len(b_files))\n",
    "            for i in range(min_len):\n",
    "                pairs.append((a_files[i], b_files[i]))\n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Image preprocessing\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            return None\n",
    "            \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        return img_rgb, gray\n",
    "    \n",
    "    def detect_face_haar(self, gray_image):\n",
    "        \"\"\"FAST face detection using candidates + simple classifier\"\"\"\n",
    "        print(\"Searching for candidate regions...\")\n",
    "        \n",
    "        candidate_regions = self._find_candidate_regions(gray_image)\n",
    "        print(f\"Found {len(candidate_regions)} candidate regions\")\n",
    "        \n",
    "        faces = []\n",
    "        \n",
    "        for i, (x, y, w, h) in enumerate(candidate_regions):\n",
    "            if i >= 10: \n",
    "                break\n",
    "                \n",
    "            region = gray_image[y:y+h, x:x+w]\n",
    "            \n",
    "            if self._is_face_region(region):\n",
    "                faces.append((x, y, w, h))\n",
    "                print(f\"Face detected in candidate region {i+1}\")\n",
    "        \n",
    "        if not faces:\n",
    "            print(\"No face detected. Using central region as fallback.\")\n",
    "            h, w = gray_image.shape\n",
    "            center_x, center_y = w//2, h//2\n",
    "            face_size = min(w, h) // 3\n",
    "            x = max(0, center_x - face_size//2)\n",
    "            y = max(0, center_y - face_size//2)\n",
    "            faces = [(x, y, face_size, face_size)]\n",
    "        \n",
    "        print(f\"Total faces detected: {len(faces)}\")\n",
    "        return np.array(faces)\n",
    "    \n",
    "    def extract_face_region(self, image, face_coords):\n",
    "        \"\"\"Extracts face region from image\"\"\"\n",
    "        if len(face_coords) == 0:\n",
    "            return None\n",
    "            \n",
    "        areas = [w * h for (x, y, w, h) in face_coords]\n",
    "        max_area_idx = np.argmax(areas)\n",
    "        x, y, w, h = face_coords[max_area_idx]\n",
    "        \n",
    "        face_region = image[y:y+h, x:x+w]\n",
    "        \n",
    "        face_region = cv2.resize(face_region, (128, 128))\n",
    "        \n",
    "        return face_region, (x, y, w, h)\n",
    "\n",
    "# Instantiate the processor\n",
    "processor = FaceRecognitionProcessor()\n",
    "print(\"Facial recognition processor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678f7590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractor initialized!\n"
     ]
    }
   ],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"Class for extracting multiple facial features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lbp_radius = 3\n",
    "        self.lbp_n_points = 8 * self.lbp_radius\n",
    "        \n",
    "    def extract_histogram_features(self, face_image):\n",
    "        \"\"\"Extraction of histogram-based features\"\"\"\n",
    "        hist = cv2.calcHist([face_image], [0], None, [256], [0, 256])\n",
    "        hist = hist.flatten()\n",
    "        hist = hist / (hist.sum() + 1e-7)  # Normalize\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def extract_lbp_features(self, face_image):\n",
    "        \"\"\"Feature extraction using Local Binary Pattern (LBP)\"\"\"\n",
    "        lbp = local_binary_pattern(face_image, self.lbp_n_points, self.lbp_radius, method='uniform')\n",
    "        \n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=self.lbp_n_points + 2, range=(0, self.lbp_n_points + 2))\n",
    "        hist = hist.astype(float)\n",
    "        hist = hist / (hist.sum() + 1e-7) \n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def extract_hog_features(self, face_image):\n",
    "        \"\"\"Feature extraction using Histogram of Oriented Gradients (HOG)\"\"\"\n",
    "        face_resized = resize(face_image, (64, 64))\n",
    "        \n",
    "        features = hog(face_resized, \n",
    "                      orientations=9,\n",
    "                      pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2), \n",
    "                      visualize=False,\n",
    "                      feature_vector=True)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_sift_features(self, face_image):\n",
    "        \"\"\"Feature extraction using SIFT\"\"\"\n",
    "        sift = cv2.SIFT_create()\n",
    "        \n",
    "        keypoints, descriptors = sift.detectAndCompute(face_image, None)\n",
    "        \n",
    "        if descriptors is not None:\n",
    "            if len(descriptors) > 30:\n",
    "                responses = [kp.response for kp in keypoints]\n",
    "                sorted_indices = np.argsort(responses)[::-1][:30]\n",
    "                descriptors = descriptors[sorted_indices]\n",
    "            \n",
    "            features = descriptors.flatten()\n",
    "            \n",
    "            fixed_size = 3840 \n",
    "            if len(features) < fixed_size:\n",
    "                padded_features = np.zeros(fixed_size)\n",
    "                padded_features[:len(features)] = features\n",
    "                features = padded_features\n",
    "            else:\n",
    "                features = features[:fixed_size]\n",
    "                \n",
    "        else:\n",
    "            features = np.zeros(3840)\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def apply_spatial_filters(self, face_image):\n",
    "        \"\"\"Application of spatial convolutional filters\"\"\"\n",
    "        face_normalized = face_image.astype(np.float32) / 255.0\n",
    "        \n",
    "        gaussian = filters.gaussian(face_normalized, sigma=1.0)\n",
    "        \n",
    "        edges_x = filters.sobel_h(face_normalized)\n",
    "        edges_y = filters.sobel_v(face_normalized)\n",
    "        edges = np.sqrt(edges_x**2 + edges_y**2)\n",
    "        \n",
    "        laplacian = filters.laplace(face_normalized)\n",
    "        \n",
    "        gaussian = (gaussian * 255).astype(np.uint8)\n",
    "        edges = (edges * 255).astype(np.uint8)\n",
    "        laplacian = (np.abs(laplacian) * 255).astype(np.uint8)\n",
    "        \n",
    "        return gaussian, edges, laplacian\n",
    "    \n",
    "    def apply_morphological_operations(self, face_image):\n",
    "        \"\"\"Application of morphological operators\"\"\"\n",
    "        kernel = morphology.disk(3)\n",
    "        \n",
    "        eroded = morphology.erosion(face_image, kernel)\n",
    "        \n",
    "        dilated = morphology.dilation(face_image, kernel)\n",
    "        \n",
    "        opened = morphology.opening(face_image, kernel)\n",
    "        \n",
    "        closed = morphology.closing(face_image, kernel)\n",
    "        \n",
    "        return eroded, dilated, opened, closed\n",
    "    \n",
    "    def apply_frequency_filters(self, face_image):\n",
    "        \"\"\"Filters in the frequency domain\"\"\"\n",
    "        f_transform = fft2(face_image)\n",
    "        f_shift = fftshift(f_transform)\n",
    "        \n",
    "        rows, cols = face_image.shape\n",
    "        crow, ccol = rows // 2, cols // 2\n",
    "        \n",
    "        sigma = 30\n",
    "        x, y = np.ogrid[:rows, :cols]\n",
    "        mask = np.exp(-((x - crow)**2 + (y - ccol)**2) / (2.0 * sigma**2))\n",
    "        \n",
    "        f_shift_filtered = f_shift * mask\n",
    "        f_ishift = fftshift(f_shift_filtered)\n",
    "        img_filtered = np.real(ifft2(f_ishift))\n",
    "        img_filtered = np.uint8(np.clip(img_filtered, 0, 255))\n",
    "        \n",
    "        return img_filtered, f_shift, mask\n",
    "    \n",
    "    def segment_face_regions(self, face_image):\n",
    "        \"\"\"Segmentation of facial image into regions\"\"\"\n",
    "        threshold_value = filters.threshold_otsu(face_image)\n",
    "        binary = face_image > threshold_value\n",
    "        \n",
    "        distance = ndimage.distance_transform_edt(binary)\n",
    "        \n",
    "        from scipy.ndimage import maximum_filter\n",
    "        local_maxima = maximum_filter(distance, size=20) == distance\n",
    "        local_maxima = local_maxima & (distance > 0.3 * distance.max())\n",
    "        \n",
    "        markers, _ = ndimage.label(local_maxima)\n",
    "        segmented = segmentation.watershed(-distance, markers, mask=binary)\n",
    "        \n",
    "        return binary.astype(np.uint8) * 255, segmented\n",
    "\n",
    "feature_extractor = FeatureExtractor()\n",
    "print(\"Feature extractor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55240563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face comparator initialized!\n"
     ]
    }
   ],
   "source": [
    "class FaceComparator:\n",
    "    \"\"\"Class for comparing facial features using multiple algorithms\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.threshold_combined = 0.60 \n",
    "        \n",
    "    def compare_histograms(self, hist1, hist2):\n",
    "        \"\"\"Histogram comparison using multiple metrics\"\"\"\n",
    "        correlation = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CORREL)\n",
    "        \n",
    "        chi_square = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CHISQR)\n",
    "        chi_square_sim = 1 / (1 + chi_square * 0.1) \n",
    "        \n",
    "        bhattacharyya = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_BHATTACHARYYA)\n",
    "        bhattacharyya_sim = 1 - bhattacharyya\n",
    "        \n",
    "        return {\n",
    "            'correlation': max(0, correlation),\n",
    "            'chi_square': max(0, chi_square_sim),\n",
    "            'bhattacharyya': max(0, bhattacharyya_sim)\n",
    "        }\n",
    "    \n",
    "    def compare_lbp_features(self, lbp1, lbp2):\n",
    "        \"\"\"LBP feature comparison\"\"\"\n",
    "        correlation = np.corrcoef(lbp1, lbp2)[0, 1]\n",
    "        if np.isnan(correlation):\n",
    "            correlation = 0\n",
    "        \n",
    "        correlation_boosted = min(1.0, correlation * 1.1)\n",
    "        return max(0, correlation_boosted)\n",
    "    \n",
    "    def compare_hog_features(self, hog1, hog2):\n",
    "        \"\"\"HOG feature comparison\"\"\"\n",
    "        dot_product = np.dot(hog1, hog2)\n",
    "        norm_product = np.linalg.norm(hog1) * np.linalg.norm(hog2)\n",
    "        \n",
    "        if norm_product == 0:\n",
    "            return 0\n",
    "            \n",
    "        cosine_similarity = dot_product / norm_product\n",
    "        \n",
    "        cosine_boosted = min(1.0, cosine_similarity * 1.1)\n",
    "        return max(0, cosine_boosted)\n",
    "    \n",
    "    def compare_sift_features(self, sift1, sift2):\n",
    "        \"\"\"SIFT feature comparison\"\"\"\n",
    "        correlation = np.corrcoef(sift1, sift2)[0, 1]\n",
    "        if np.isnan(correlation):\n",
    "            correlation = 0\n",
    "        \n",
    "        if correlation < 0.2:\n",
    "            correlation = correlation * 2.0  \n",
    "        \n",
    "        return max(0, min(1.0, correlation))\n",
    "    \n",
    "    def compute_similarity_score(self, face1_features, face2_features):\n",
    "        \"\"\"Computes similarity score combining all algorithms\"\"\"\n",
    "        scores = {}\n",
    "        \n",
    "        if 'histogram' in face1_features and 'histogram' in face2_features:\n",
    "            hist_scores = self.compare_histograms(face1_features['histogram'], face2_features['histogram'])\n",
    "            scores.update({f'histogram_{k}': v for k, v in hist_scores.items()})\n",
    "        \n",
    "        if 'lbp' in face1_features and 'lbp' in face2_features:\n",
    "            lbp_score = self.compare_lbp_features(face1_features['lbp'], face2_features['lbp'])\n",
    "            scores['lbp_similarity'] = lbp_score\n",
    "        \n",
    "        if 'hog' in face1_features and 'hog' in face2_features:\n",
    "            hog_score = self.compare_hog_features(face1_features['hog'], face2_features['hog'])\n",
    "            scores['hog_similarity'] = hog_score\n",
    "        \n",
    "        if 'sift' in face1_features and 'sift' in face2_features:\n",
    "            sift_score = self.compare_sift_features(face1_features['sift'], face2_features['sift'])\n",
    "            scores['sift_similarity'] = sift_score\n",
    "        \n",
    "        weights = {\n",
    "            'histogram_correlation': 0.08,     \n",
    "            'histogram_chi_square': 0.07,     \n",
    "            'histogram_bhattacharyya': 0.10,   \n",
    "            'lbp_similarity': 0.30,           \n",
    "            'hog_similarity': 0.35,            \n",
    "            'sift_similarity': 0.10            \n",
    "        }\n",
    "        \n",
    "        weighted_sum = sum(scores.get(key, 0) * weight for key, weight in weights.items())\n",
    "        total_weight = sum(weights[key] for key in weights.keys() if key in scores)\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            final_score = weighted_sum / total_weight\n",
    "        else:\n",
    "            final_score = 0\n",
    "            \n",
    "        high_scores = sum(1 for key in ['lbp_similarity', 'hog_similarity'] if scores.get(key, 0) > 0.8)\n",
    "        if high_scores >= 2:\n",
    "            final_score = min(1.0, final_score * 1.05)  \n",
    "            \n",
    "        return final_score, scores\n",
    "    \n",
    "    def classify_same_person(self, similarity_score, threshold=None):\n",
    "        \"\"\"Classifies if the faces belong to the same person\"\"\"\n",
    "        if threshold is None:\n",
    "            threshold = self.threshold_combined\n",
    "            \n",
    "        is_same_person = similarity_score >= threshold\n",
    "        confidence = similarity_score\n",
    "        \n",
    "        return is_same_person, confidence\n",
    "    \n",
    "    def analyze_algorithm_performance(self, detailed_scores):\n",
    "        \"\"\"Analyzes the performance of each algorithm individually\"\"\"\n",
    "        algorithm_scores = {\n",
    "            'histogram': np.mean([\n",
    "                detailed_scores.get('histogram_correlation', 0),\n",
    "                detailed_scores.get('histogram_chi_square', 0),\n",
    "                detailed_scores.get('histogram_bhattacharyya', 0)\n",
    "            ]),\n",
    "            'lbp': detailed_scores.get('lbp_similarity', 0),\n",
    "            'hog': detailed_scores.get('hog_similarity', 0),\n",
    "            'sift': detailed_scores.get('sift_similarity', 0)\n",
    "        }\n",
    "        \n",
    "        best_algorithm = max(algorithm_scores.items(), key=lambda x: x[1])\n",
    "        worst_algorithm = min(algorithm_scores.items(), key=lambda x: x[1])\n",
    "        \n",
    "        return {\n",
    "            'algorithm_scores': algorithm_scores,\n",
    "            'best_algorithm': best_algorithm,\n",
    "            'worst_algorithm': worst_algorithm\n",
    "        }\n",
    "\n",
    "face_comparator = FaceComparator()\n",
    "print(\"Face comparator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deecd635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing function defined!\n"
     ]
    }
   ],
   "source": [
    "def process_face_pair(image_path1, image_path2, show_details=True):\n",
    "    \"\"\"\n",
    "    Processes a pair of images to determine if they contain the same person\n",
    "    using multiple image processing algorithms\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'image1': image_path1,\n",
    "        'image2': image_path2,\n",
    "        'faces_detected': [False, False],\n",
    "        'similarity_score': 0.0,\n",
    "        'same_person': False,\n",
    "        'detailed_scores': {},\n",
    "        'processing_steps': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing image pair:\")\n",
    "    print(f\"Original Image (A): {os.path.basename(image_path1)}\")\n",
    "    print(f\"Transformed Image (B): {os.path.basename(image_path2)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    img1_rgb, img1_gray = processor.preprocess_image(image_path1)\n",
    "    img2_rgb, img2_gray = processor.preprocess_image(image_path2)\n",
    "    \n",
    "    if img1_rgb is None or img2_rgb is None:\n",
    "        print(\"Error loading one or both images!\")\n",
    "        return results\n",
    "    \n",
    "    faces1 = processor.detect_face_haar(img1_gray)\n",
    "    faces2 = processor.detect_face_haar(img2_gray)\n",
    "    \n",
    "    results['faces_detected'] = [len(faces1) > 0, len(faces2) > 0]\n",
    "    \n",
    "    if len(faces1) == 0 or len(faces2) == 0:\n",
    "        print(\"Face not detected in one or both images!\")\n",
    "        return results\n",
    "    \n",
    "    face1, coords1 = processor.extract_face_region(img1_gray, faces1)\n",
    "    face2, coords2 = processor.extract_face_region(img2_gray, faces2)\n",
    "    \n",
    "    if face1 is None or face2 is None:\n",
    "        print(\"Error extracting facial regions!\")\n",
    "        return results\n",
    "    \n",
    "    face1_gaussian, face1_edges, face1_laplacian = feature_extractor.apply_spatial_filters(face1)\n",
    "    face2_gaussian, face2_edges, face2_laplacian = feature_extractor.apply_spatial_filters(face2)\n",
    "    \n",
    "    face1_eroded, face1_dilated, face1_opened, face1_closed = feature_extractor.apply_morphological_operations(face1)\n",
    "    face2_eroded, face2_dilated, face2_opened, face2_closed = feature_extractor.apply_morphological_operations(face2)\n",
    "    \n",
    "    face1_freq, f1_shift, mask1 = feature_extractor.apply_frequency_filters(face1)\n",
    "    face2_freq, f2_shift, mask2 = feature_extractor.apply_frequency_filters(face2)\n",
    "    \n",
    "    face1_binary, face1_segmented = feature_extractor.segment_face_regions(face1)\n",
    "    face2_binary, face2_segmented = feature_extractor.segment_face_regions(face2)\n",
    "    \n",
    "    hist1 = feature_extractor.extract_histogram_features(face1)\n",
    "    hist2 = feature_extractor.extract_histogram_features(face2)\n",
    "    \n",
    "    lbp1 = feature_extractor.extract_lbp_features(face1)\n",
    "    lbp2 = feature_extractor.extract_lbp_features(face2)\n",
    "    \n",
    "    hog1 = feature_extractor.extract_hog_features(face1)\n",
    "    hog2 = feature_extractor.extract_hog_features(face2)\n",
    "    \n",
    "    sift1 = feature_extractor.extract_sift_features(face1)\n",
    "    sift2 = feature_extractor.extract_sift_features(face2)\n",
    "    \n",
    "    features1 = {\n",
    "        'histogram': hist1,\n",
    "        'lbp': lbp1,\n",
    "        'hog': hog1,\n",
    "        'sift': sift1\n",
    "    }\n",
    "    \n",
    "    features2 = {\n",
    "        'histogram': hist2,\n",
    "        'lbp': lbp2,\n",
    "        'hog': hog2,\n",
    "        'sift': sift2\n",
    "    }\n",
    "    \n",
    "    similarity_score, detailed_scores = face_comparator.compute_similarity_score(features1, features2)\n",
    "    same_person, confidence = face_comparator.classify_same_person(similarity_score)\n",
    "    \n",
    "    results['similarity_score'] = similarity_score\n",
    "    results['same_person'] = same_person\n",
    "    results['detailed_scores'] = detailed_scores\n",
    "    \n",
    "    algorithm_analysis = face_comparator.analyze_algorithm_performance(detailed_scores)\n",
    "    results['algorithm_analysis'] = algorithm_analysis\n",
    "    \n",
    "    results['processing_steps'] = {\n",
    "        'original': [img1_rgb, img2_rgb],\n",
    "        'gray': [img1_gray, img2_gray],\n",
    "        'faces': [face1, face2],\n",
    "        'face_coords': [coords1, coords2],\n",
    "        'spatial_filters': {\n",
    "            'gaussian': [face1_gaussian, face2_gaussian],\n",
    "            'edges': [face1_edges, face2_edges],\n",
    "            'laplacian': [face1_laplacian, face2_laplacian]\n",
    "        },\n",
    "        'morphological': {\n",
    "            'eroded': [face1_eroded, face2_eroded],\n",
    "            'dilated': [face1_dilated, face2_dilated],\n",
    "            'opened': [face1_opened, face2_opened],\n",
    "            'closed': [face1_closed, face2_closed]\n",
    "        },\n",
    "        'frequency_filters': [face1_freq, face2_freq],\n",
    "        'segmentation': {\n",
    "            'binary': [face1_binary, face2_binary],\n",
    "            'segmented': [face1_segmented, face2_segmented]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nRESULTS:\")\n",
    "    print(f\"Same Person: {'YES' if same_person else 'NO'}\")\n",
    "    print(f\"Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Processing function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600a2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main pipeline defined!\n",
      "Configured for complete processing with multiple image processing algorithms!\n"
     ]
    }
   ],
   "source": [
    "def main_face_recognition_pipeline(data_dir=\"./data\", show_visualizations=False):\n",
    "    \"\"\"\n",
    "    Main facial recognition pipeline\n",
    "    Processes all image pairs in the directory using multiple algorithms\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"FACIAL RECOGNITION SYSTEM - PAIR COMPARISON\")\n",
    "    print(\"Algorithms used: Haar Features, LBP, HOG, SIFT, Spatial and Frequency Filters\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Directory {data_dir} not found!\")\n",
    "        return\n",
    "    \n",
    "    pairs = processor.load_image_pairs(data_dir)\n",
    "    \n",
    "    if not pairs:\n",
    "        print(\"No image pairs found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(pairs)} image pairs for processing.\")\n",
    "    print(f\"Directory: {data_dir}\")\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for i, (img1_path, img2_path) in enumerate(pairs, 1):\n",
    "        print(f\"\\n[PROCESSING PAIR {i}/{len(pairs)}]\")\n",
    "        \n",
    "        result = process_face_pair(img1_path, img2_path, show_details=show_visualizations)\n",
    "        results_summary.append(result)\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    total_pairs = len(results_summary)\n",
    "    same_person_count = sum(1 for r in results_summary if r['same_person'])\n",
    "    faces_detected_count = sum(1 for r in results_summary if all(r['faces_detected']))\n",
    "    \n",
    "    print(f\"Total pairs processed: {total_pairs}\")\n",
    "    print(f\"Pairs with faces detected: {faces_detected_count}\")\n",
    "    print(f\"Pairs identified as same person: {same_person_count}\")\n",
    "    print(f\"Match rate: {same_person_count/faces_detected_count*100:.1f}%\" if faces_detected_count > 0 else \"N/A\")\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "print(\"Main pipeline defined!\")\n",
    "print(\"Configured for complete processing with multiple image processing algorithms!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d1a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available images in directory:\n",
      "==================================================\n",
      "Total files found: 16\n",
      "\\nFile list:\n",
      " 1. A01.jpg (6.7 KB)\n",
      " 2. A02.jpg (9.4 KB)\n",
      " 3. A03.jpg (7.4 KB)\n",
      " 4. A04.jpg (7.9 KB)\n",
      " 5. A05.jpg (8.4 KB)\n",
      " 6. A06.jpg (6.9 KB)\n",
      " 7. A07.jpg (8.3 KB)\n",
      " 8. A08.jpg (11.3 KB)\n",
      " 9. A09.jpg (8.9 KB)\n",
      "10. A10.jpg (8.3 KB)\n",
      "11. B01.jpg (10.6 KB)\n",
      "12. B04.jpg (8.1 KB)\n",
      "13. B05.jpg (10.5 KB)\n",
      "14. B07.jpg (9.9 KB)\n",
      "15. B08.jpg (12.8 KB)\n",
      "16. B09.jpg (9.1 KB)\n",
      "Found 10 original images (A) and 6 transformed images (B)\n",
      "Pair created: A01.jpg <-> B01.jpg\n",
      "Pair created: A04.jpg <-> B04.jpg\n",
      "Pair created: A05.jpg <-> B05.jpg\n",
      "Pair created: A07.jpg <-> B07.jpg\n",
      "Pair created: A08.jpg <-> B08.jpg\n",
      "Pair created: A09.jpg <-> B09.jpg\n",
      "\\nPairs to be processed: 6\n",
      "Pair 1: A01.jpg <-> B01.jpg\n",
      "Pair 2: A04.jpg <-> B04.jpg\n",
      "Pair 3: A05.jpg <-> B05.jpg\n",
      "Pair 4: A07.jpg <-> B07.jpg\n",
      "Pair 5: A08.jpg <-> B08.jpg\n",
      "Pair 6: A09.jpg <-> B09.jpg\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"./data\"\n",
    "\n",
    "print(\"Checking available images in directory:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if os.path.exists(data_directory):\n",
    "    image_files = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "        image_files.extend(glob.glob(os.path.join(data_directory, ext)))\n",
    "    \n",
    "    image_files = sorted(image_files)\n",
    "    \n",
    "    print(f\"Total files found: {len(image_files)}\")\n",
    "    print(\"\\\\nFile list:\")\n",
    "    \n",
    "    for i, file_path in enumerate(image_files, 1):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"{i:2d}. {file_name} ({file_size:.1f} KB)\")\n",
    "    \n",
    "\n",
    "    pairs = processor.load_image_pairs(data_directory)\n",
    "    print(f\"\\\\nPairs to be processed: {len(pairs)}\")\n",
    "    for i, (img1, img2) in enumerate(pairs, 1):\n",
    "        print(f\"Pair {i}: {os.path.basename(img1)} <-> {os.path.basename(img2)}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Directory {data_directory} not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc303a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FACIAL RECOGNITION SYSTEM - PAIR COMPARISON\n",
      "Algorithms used: Haar Features, LBP, HOG, SIFT, Spatial and Frequency Filters\n",
      "================================================================================\n",
      "Found 10 original images (A) and 6 transformed images (B)\n",
      "Pair created: A01.jpg <-> B01.jpg\n",
      "Pair created: A04.jpg <-> B04.jpg\n",
      "Pair created: A05.jpg <-> B05.jpg\n",
      "Pair created: A07.jpg <-> B07.jpg\n",
      "Pair created: A08.jpg <-> B08.jpg\n",
      "Pair created: A09.jpg <-> B09.jpg\n",
      "\n",
      "Found 6 image pairs for processing.\n",
      "Directory: ./data\n",
      "\n",
      "[PROCESSING PAIR 1/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A01.jpg\n",
      "Transformed Image (B): B01.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 1 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.720\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 2/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A04.jpg\n",
      "Transformed Image (B): B04.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.716\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 3/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A05.jpg\n",
      "Transformed Image (B): B05.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 2 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.751\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 4/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A07.jpg\n",
      "Transformed Image (B): B07.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.751\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 4/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A07.jpg\n",
      "Transformed Image (B): B07.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.800\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 5/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A08.jpg\n",
      "Transformed Image (B): B08.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.800\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 5/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A08.jpg\n",
      "Transformed Image (B): B08.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.777\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 6/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A09.jpg\n",
      "Transformed Image (B): B09.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.777\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING PAIR 6/6]\n",
      "\n",
      "============================================================\n",
      "Processing image pair:\n",
      "Original Image (A): A09.jpg\n",
      "Transformed Image (B): B09.jpg\n",
      "============================================================\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "Searching for candidate regions...\n",
      "Found 0 candidate regions\n",
      "No face detected. Using central region as fallback.\n",
      "Total faces detected: 1\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.757\n",
      "------------------------------------------------------------\n",
      "Total pairs processed: 6\n",
      "Pairs with faces detected: 6\n",
      "Pairs identified as same person: 6\n",
      "Match rate: 100.0%\n",
      "\n",
      "FINAL CONCLUSION:\n",
      "----------------------------------------\n",
      "Most effective algorithm: LBP (0.975)\n",
      "Least effective algorithm: SIFT (0.314)\n",
      "Overall average score: 0.754\n",
      "Accuracy rate: 100.0%\n",
      "\n",
      "RESULTS:\n",
      "Same Person: YES\n",
      "Confidence: 0.757\n",
      "------------------------------------------------------------\n",
      "Total pairs processed: 6\n",
      "Pairs with faces detected: 6\n",
      "Pairs identified as same person: 6\n",
      "Match rate: 100.0%\n",
      "\n",
      "FINAL CONCLUSION:\n",
      "----------------------------------------\n",
      "Most effective algorithm: LBP (0.975)\n",
      "Least effective algorithm: SIFT (0.314)\n",
      "Overall average score: 0.754\n",
      "Accuracy rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "all_results = main_face_recognition_pipeline(data_directory, show_visualizations=False)\n",
    "\n",
    "if all_results:\n",
    "    \n",
    "    histogram_scores = []\n",
    "    lbp_scores = []\n",
    "    hog_scores = []\n",
    "    sift_scores = []\n",
    "    combined_scores = []\n",
    "    \n",
    "    for result in all_results:\n",
    "        if result['detailed_scores'] and result['algorithm_analysis']:\n",
    "            histogram_scores.append(result['algorithm_analysis']['algorithm_scores'].get('histogram', 0))\n",
    "            lbp_scores.append(result['algorithm_analysis']['algorithm_scores'].get('lbp', 0))\n",
    "            hog_scores.append(result['algorithm_analysis']['algorithm_scores'].get('hog', 0))\n",
    "            sift_scores.append(result['algorithm_analysis']['algorithm_scores'].get('sift', 0))\n",
    "            combined_scores.append(result['similarity_score'])\n",
    "    \n",
    "    if histogram_scores:\n",
    "        algorithm_means = {\n",
    "            'Histogram': np.mean(histogram_scores),\n",
    "            'LBP': np.mean(lbp_scores),\n",
    "            'HOG': np.mean(hog_scores),\n",
    "            'SIFT': np.mean(sift_scores)\n",
    "        }\n",
    "        \n",
    "        ranked_algorithms = sorted(algorithm_means.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\nFINAL CONCLUSION:\")\n",
    "        print(\"-\" * 40)\n",
    "        best_algorithm = ranked_algorithms[0]\n",
    "        worst_algorithm = ranked_algorithms[-1]\n",
    "        \n",
    "        print(f\"Most effective algorithm: {best_algorithm[0]} ({best_algorithm[1]:.3f})\")\n",
    "        print(f\"Least effective algorithm: {worst_algorithm[0]} ({worst_algorithm[1]:.3f})\")\n",
    "        print(f\"Overall average score: {np.mean(combined_scores):.3f}\")\n",
    "        print(f\"Accuracy rate: {np.mean([r['same_person'] for r in all_results]) * 100:.1f}%\")\n",
    "        \n",
    "else:\n",
    "    print(\"No results to analyze!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
